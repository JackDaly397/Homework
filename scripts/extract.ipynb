{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gicUEe1hOBDP"
      },
      "outputs": [],
      "source": [
        "!pip install azure-storage-blob\n",
        "!pip install boto3\n",
        "!pip install google-cloud-storage\n",
        "!pip install sodapy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "DdJ-2JsVG3c6"
      },
      "outputs": [],
      "source": [
        "#import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "import requests\n",
        "import boto3\n",
        "from azure.storage.blob import BlobServiceClient, BlobClient, ContainerClient\n",
        "from google.cloud import storage\n",
        "from io import StringIO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fUvaAkSoJZ6m"
      },
      "source": [
        "s1 --> Gather --> Decompress --> Convert to Tabular --> Clean --> Reformat --> Consolidate --> Tranformation --> Load"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "fBej0kFlRabF"
      },
      "outputs": [],
      "source": [
        "from sodapy import Socrata\n",
        "import pandas as pd\n",
        "from sodapy import Socrata\n",
        "\n",
        "data_url='data.cityofnewyork.us'    # The Host Name for the API endpoint (the https:// part will be added automatically)\n",
        "data_set='vww9-qguh'    # The data set at the API endpoint (311 data in this case)\n",
        "app_token='m93ORKHDVAEgZJ48OfuDNs5sI'   # The app token created in the prior steps\n",
        "client = Socrata(data_url,app_token)      # Create the client to point to the API endpoint\n",
        "# Set the timeout to 60 seconds\n",
        "client.timeout = 60\n",
        "# Retrieve the first 2000 results returned as JSON object from the API\n",
        "# The SoDaPy library converts this JSON object to a Python list of dictionaries\n",
        "results = client.get(data_set, limit=2000)\n",
        "# Convert the list of dictionaries to a Pandas data frame\n",
        "df = pd.DataFrame.from_records(results)\n",
        "# Save the data frame to a CSV file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "NuuN9M7tSSVn"
      },
      "outputs": [],
      "source": [
        "# Function\n",
        "\n",
        "import os\n",
        "import boto3\n",
        "from azure.storage.blob import BlobServiceClient\n",
        "from google.cloud import storage\n",
        "import pandas as pd\n",
        "from io import BytesIO, StringIO\n",
        "\n",
        "# Azure Functions\n",
        "def azure_upload_blob(connect_str, container_name, blob_name, data):\n",
        "    blob_service_client = BlobServiceClient.from_connection_string(connect_str)\n",
        "    blob_client = blob_service_client.get_blob_client(container=container_name, blob=blob_name)\n",
        "    blob_client.upload_blob(data, overwrite=True)\n",
        "    print(f\"Uploaded to Azure Blob: {blob_name}\")\n",
        "\n",
        "def azure_download_blob(connect_str, container_name, blob_name):\n",
        "    blob_service_client = BlobServiceClient.from_connection_string(connect_str)\n",
        "    blob_client = blob_service_client.get_blob_client(container=container_name, blob=blob_name)\n",
        "    download_stream = blob_client.download_blob()\n",
        "    return download_stream.readall()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8pwg7j8Sgru7",
        "outputId": "140668d6-3bb9-4815-f450-f4709d7e36a1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 2000 entries, 0 to 1999\n",
            "Data columns (total 13 columns):\n",
            " #   Column                      Non-Null Count  Dtype \n",
            "---  ------                      --------------  ----- \n",
            " 0   dbn                         2000 non-null   object\n",
            " 1   school_name                 2000 non-null   object\n",
            " 2   grade                       2000 non-null   object\n",
            " 3   year                        2000 non-null   object\n",
            " 4   demographic_category        2000 non-null   object\n",
            " 5   demographic_variable        2000 non-null   object\n",
            " 6   total_days                  2000 non-null   object\n",
            " 7   days_absent                 2000 non-null   object\n",
            " 8   days_present                2000 non-null   object\n",
            " 9   attendance                  2000 non-null   object\n",
            " 10  contributing_20_total_days  2000 non-null   object\n",
            " 11  chronically_absent          2000 non-null   object\n",
            " 12  chronically_absent_1        2000 non-null   object\n",
            "dtypes: object(13)\n",
            "memory usage: 203.2+ KB\n"
          ]
        }
      ],
      "source": [
        "from sodapy import Socrata\n",
        "import pandas as pd\n",
        "from sodapy import Socrata\n",
        "\n",
        "data_url='data.cityofnewyork.us'    # The Host Name for the API endpoint (the https:// part will be added automatically)\n",
        "data_set='vww9-qguh'    # The data set at the API endpoint (311 data in this case)\n",
        "app_token='m93ORKHDVAEgZJ48OfuDNs5sI'   # The app token created in the prior steps\n",
        "client = Socrata(data_url,app_token)      # Create the client to point to the API endpoint\n",
        "# Set the timeout to 60 seconds\n",
        "client.timeout = 60\n",
        "# Retrieve the first 2000 results returned as JSON object from the API\n",
        "# The SoDaPy library converts this JSON object to a Python list of dictionaries\n",
        "results = client.get(data_set, limit=2000)\n",
        "# Convert the list of dictionaries to a Pandas data frame\n",
        "df_raw = pd.DataFrame.from_records(results)\n",
        "df_raw.dropna()\n",
        "df_raw.shape\n",
        "df_raw.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "2exf8qt-Lemx"
      },
      "outputs": [],
      "source": [
        "df_clean = df_raw.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ynv0kFcfL4p2",
        "outputId": "3a9e7e8a-1131-43fc-984f-10e2d806faa2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 56551 entries, 0 to 56550\n",
            "Data columns (total 19 columns):\n",
            " #   Column                 Non-Null Count  Dtype         \n",
            "---  ------                 --------------  -----         \n",
            " 0   VendorID               56551 non-null  int32         \n",
            " 1   lpep_pickup_datetime   56551 non-null  datetime64[ns]\n",
            " 2   lpep_dropoff_datetime  56551 non-null  datetime64[ns]\n",
            " 3   store_and_fwd_flag     53136 non-null  object        \n",
            " 4   RatecodeID             53136 non-null  float64       \n",
            " 5   PULocationID           56551 non-null  int32         \n",
            " 6   DOLocationID           56551 non-null  int32         \n",
            " 7   passenger_count        53136 non-null  float64       \n",
            " 8   trip_distance          56551 non-null  float64       \n",
            " 9   fare_amount            56551 non-null  float64       \n",
            " 10  extra                  56551 non-null  float64       \n",
            " 11  mta_tax                56551 non-null  float64       \n",
            " 12  tip_amount             56551 non-null  float64       \n",
            " 13  tolls_amount           56551 non-null  float64       \n",
            " 14  improvement_surcharge  56551 non-null  float64       \n",
            " 15  total_amount           56551 non-null  float64       \n",
            " 16  payment_type           53136 non-null  float64       \n",
            " 17  trip_type              53133 non-null  float64       \n",
            " 18  congestion_surcharge   53136 non-null  float64       \n",
            "dtypes: datetime64[ns](2), float64(13), int32(3), object(1)\n",
            "memory usage: 7.6+ MB\n"
          ]
        }
      ],
      "source": [
        "df_clean = df_raw.drop(columns = ['ehail_fee'])\n",
        "df_clean.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wCjjD6utNLrq"
      },
      "source": [
        "Create Connection to Azure Container\n",
        "- connection string"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gjCRbCCnNUdq"
      },
      "outputs": [],
      "source": [
        "#specify the path to your JSON configuration file\n",
        "config_file_path = 'config.json'\n",
        "\n",
        "#load the JSON configuration file\n",
        "with open(config_file_path, 'r') as config_file\n",
        "    config = json.load(config_file)\n",
        "\n",
        "#print the configuration\n",
        "#Connection_STRING = config['CONNECTION_STRING_AZURE_STORAGE']\n",
        "\n",
        "CONNECTION_STRING_AZURE_STORAGE = config['connectionString']\n",
        "CONTAINER_AZURE = 'studentattendance'\n",
        "blob_name = 'nycatt.csv'\n",
        "\n",
        "# Convert DataFrame to CSV\n",
        "output = StringIO()\n",
        "df_raw.to_csv(output, index=False)\n",
        "data = output.getvalue()\n",
        "output.close()\n",
        "\n",
        "# Create the BlobServiceClient object\n",
        "blob_service_client = BlobServiceClient.from_connection_string(CONNECTION_STRING_AZURE_STORAGE)\n",
        "\n",
        "# Get a blob client using the container name and blob name\n",
        "blob_client = blob_service_client.get_blob_client(container=CONTAINER_AZURE, blob=blob_name)\n",
        "\n",
        "# Upload the CSV data\n",
        "blob_client.upload_blob(data, overwrite=True)\n",
        "\n",
        "print(f\"Uploaded {blob_name} to Azure Blob Storage in container {CONTAINER_AZURE}.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OaXloXP3hcx1"
      },
      "outputs": [],
      "source": [
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    output = StringIO()\n",
        "    df_raw.to_csv(output, index=False)\n",
        "    data = output.getvalue()\n",
        "    output.close()\n",
        "\n",
        "    # Azure\n",
        "    azure_connect_str = 'YOUR_AZURE_STORAGE_CONNECTION_STRING'\n",
        "    azure_container_name = 'YOUR_CONTAINER_NAME'\n",
        "    azure_blob_name = 'your_blob_name.csv'\n",
        "    azure_data = 'Hello, Azure!'\n",
        "    azure_upload_blob(azure_connect_str, azure_container_name, azure_blob_name, azure_data)\n",
        "    # Download and print the blob content\n",
        "    azure_blob_content = azure_download_blob(azure_connect_str, azure_container_name, azure_blob_name)\n",
        "    print(azure_blob_content)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
